# q_recall
**Post-RAG era Search Framework â€” Context-Rich, Index-Free**

`q_recall` is a lightweight, Keras-like agentic search framework built for the **post-RAG era**.
It combines **LLM-driven reasoning** with, **Zero indexing**, **direct file search (grep + glob)**, **reference following**, and **context enrichment** â€” allowing agents to *read and reason end-to-end*, without embeddings or indexing.

> _"Retrieval was for context-poor models. Agentic search is for context-rich intelligence."_

---

## ğŸš€ Why q_recall?

In the new context-abundant world (2M+ tokens), we no longer need heavy RAG pipelines.
`q_recall` adopts the Claude Code philosophy â€” **no vector DB, no chunking, no reranking** â€” just smart agents that **navigate, reason, and follow references** across live files.

### Key Ideas
- **Zero-index, live filesystem search** â€” instant availability of new docs
- **Composable pipelines** â€” build agentic stacks like `keras.Sequential`
- **Branching, looping, planning** â€” for true multi-step, investigative agents
- **Traceable execution** â€” every step is logged
- **LLM-ready hooks** â€” plug in real LLMs for extraction or answering

---

## ğŸ§© Quick Start

### Install
```bash
git clone https://github.com/yourname/q_recall.git
cd q_recall
pip install -e .
```

### Run an Example
```bash
python examples/basic.py
```

---

## ğŸ§  Minimal Example

```python
import q_recall as qr

db = qr.ParadigmDB()
db.register_fs("data", "./data")

mem0 = qr.Stack(
    qr.MultilingualNormalizer(),
    qr.Branch(
        qr.Stack(qr.Grep(dir="data"), qr.Ranking(max_candidates=10)),
        qr.Stack(qr.Glob(dir="data"), qr.Ranking(max_candidates=5)),
    ),
    qr.Deduplicate(),
    qr.ContextEnricher(max_tokens=1000),
    qr.Concat(max_window_size=10_000),
    qr.ComposeAnswer()
)

state = mem0(qr.State(query=qr.Query(text="Describe a counter-dependent personality")))
print(state.answer)
```

## ğŸ›  Self-Healing Search Agent

`q_recall` supports agentic recovery behaviors via `Planner` + `Loop`.
A self-healing pipeline detects when search results are missing, weak, or irrelevant â€” and automatically expands, reformulates, or redirects the query until useful evidence is found.


---

## ğŸ§± Core Concepts

### The Building Blocks

| Component | Purpose |
|------------|----------|
| `Grep` | Fast, regex-based content search through files |
| `Glob` | File discovery by name pattern |
| `Ranking` | Simple scoring and filtering |
| `ContextEnricher` | Expands snippets into readable context |
| `Concat` | Combines multiple candidates into one evidence block |
| `ComposeAnswer` | Generates final answer (LLM hook ready) |
| `Stack` | Sequential composition (like `keras.Sequential`) |
| `Branch` | Parallel paths (like `keras.Functional`) |
| `Loop` | Iterative refinement until convergence |
| `ReferenceFollower` | Detects and follows references (e.g., â€œSee Note 12â€) |
| `Planner` | Expands or rephrases queries if nothing found |

---

## ğŸ§® Architecture Overview

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Query()    â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Term Extract â”‚ â† optional LLM
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                    â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Grep()  â”‚         â”‚  Glob()  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼                    â–¼
        â””â”€â”€â”€â”€â”€â”€â”€â–º Merge â–ºâ”€â”€â”€â”€â”˜
                 â”‚
             Ranking()
                 â”‚
         ContextEnricher()
                 â”‚
              Concat()
                 â”‚
          ComposeAnswer()
```

---

## âš™ï¸ Example Pipelines

### 1. Basic Search (English example)
```python
mem0 = qr.Stack(
    qr.MultilingualNormalizer(),
    qr.Grep(dir="data"),
    qr.Ranking(max_candidates=10),
    qr.ContextEnricher(max_tokens=1000),
    qr.Concat(max_window_size=10_000),
    qr.ComposeAnswer()
)
```

### 2. SEC Filings Agent (Reference Following)
```python
lease_agent = qr.Stack(
    qr.Grep(dir="sec"),
    qr.Ranking(max_candidates=20),
    qr.ContextEnricher(max_tokens=2000),
    qr.Concat(max_window_size=80_000),
    qr.ReferenceFollower(dir="sec"),
    qr.Ranking(max_candidates=30, keyword_boost=["lease", "Note", "Item 7"]),
    qr.Concat(max_window_size=160_000),
    qr.ComposeAnswer(prompt="Compute final lease obligations with adjustments:")
)
```

### 3. Branching Code Search
```python
code_search = qr.Stack(
    qr.Branch(
        qr.Stack(qr.Grep(dir="repo"), qr.Ranking(max_candidates=25)),
        qr.Stack(qr.Glob(dir="repo", pattern="src/**/*.*"), qr.Ranking(max_candidates=10)),
    ),
    qr.Deduplicate(),
    qr.ContextEnricher(max_tokens=1500),
    qr.Concat(max_window_size=50_000),
    qr.ComposeAnswer(prompt="Summarize implementation details with file paths.")
)
```

---

## ğŸ“¦ Project Structure

```
q_recall/
â”œâ”€â”€ q_recall/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py
â”‚   â”œâ”€â”€ ops_search.py
â”‚   â”œâ”€â”€ ops_rank.py
â”‚   â”œâ”€â”€ ops_agent.py
â”‚   â”œâ”€â”€ answer.py
â”‚   â”œâ”€â”€ db.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic.py
â”‚   â””â”€â”€ sec_lease.py
â”œâ”€â”€ README.md
â””â”€â”€ pyproject.toml
```

---

## ğŸ”¬ Design Philosophy

- **Direct reasoning over raw data**
  Agents read entire files and follow references â€” no artificial fragmentation.

- **Composable like Keras**
  `Stack` pipelines mirror deep learning model assembly: simple, declarative, inspectable.

- **Transparent execution**
  Every op logs its behavior into the `State.trace`, so you can audit the reasoning chain.

- **LLM Optional**
  Everything runs offline. Plug in real LLM calls only for term extraction or final synthesis.

---

## ğŸ§© Extending the Framework

```python
from q_recall.core import State
from q_recall.ops_agent import Op

class MyFilter(Op):
    def forward(self, state: State) -> State:
        state.candidates = [c for c in state.candidates if "important" in c.snippet.lower()]
        state.log("myfilter", kept=len(state.candidates))
        return state
```

---

## ğŸ§° Planned Extensions

- Smarter `ReferenceFollower`
- Autonomous `Planner`
- Caching and budget control
- LLM-structured answering

---

## ğŸ§‘â€ğŸ’» License

MIT License Â© 2025
